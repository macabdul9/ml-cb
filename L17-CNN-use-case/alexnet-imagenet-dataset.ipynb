{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "QsD0CFhii2e_",
    "outputId": "959a78ac-91ee-463e-ee0d-5ddee44c3235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wP5s24r-1QCC"
   },
   "outputs": [],
   "source": [
    "# !unzip drive/My\\ Drive/tiny-imagenet-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3O9xBMg56Lvx"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJA-_d6JxYxw"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtTrbfU5oJf-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JIhnfe3domGB",
    "outputId": "c80f1944-26b5-4e20-9f4e-5942415b5401"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras_preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hACD28BQXWrS"
   },
   "source": [
    "#### Data Pipeline image-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6txUkb1XVly"
   },
   "outputs": [],
   "source": [
    "train_img_gen = image.ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range = 180,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.4,\n",
    "    zoom_range = 0.3,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# we don't need to do augmentation for test data\n",
    "test_img_gen = image.ImageDataGenerator(\n",
    "    rescale = 1/255.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VZoKJSaGXR0V",
    "outputId": "bb54cd3b-97a9-41b6-8883-5e49afa9d4cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_img_gen.flow_from_directory(\n",
    "    'tiny-imagenet-200/train/',\n",
    "    target_size = ((224, 224)),\n",
    "    batch_size = 1024,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")\n",
    "test_gen = test_img_gen.flow_from_directory(\n",
    "    'tiny-imagenet-200/test/',\n",
    "    target_size = ((224, 224)),\n",
    "    batch_size = 512,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v5CRMUVCFjhQ",
    "outputId": "dd51b69c-9559-40ee-fbe4-209d7b3f787e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 224, 224, 3) (512, 200)\n"
     ]
    }
   ],
   "source": [
    "for (x, y) in train_gen:\n",
    "  print(x.shape, y.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fV54PS3rRMG"
   },
   "outputs": [],
   "source": [
    "# validation data processing, since it is different form\n",
    "\n",
    "class_ids = train_gen.class_indices\n",
    "\n",
    "def load_validation_data(target_size, number_of_classes):\n",
    "  with open('tiny-imagenet-200/val/val_annotations.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    m = len(lines)\n",
    "    X = np.empty((m, *target_size, 3))\n",
    "    Y = np.empty(m)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "      token = line.split()\n",
    "      img_name = token[0]\n",
    "      img_label = token[1]\n",
    "      \n",
    "      img_url = os.path.join('tiny-imagenet-200/val/images', img_name)\n",
    "      \n",
    "      img = image.load_img(img_url)\n",
    "      img = img.resize(target_size)\n",
    "      X[i, ] = np.array(img, dtype=np.float32)/255.0\n",
    "      img.close()\n",
    "      Y[i] = class_ids[img_label]\n",
    "      \n",
    "    return X, keras.utils.np_utils.to_categorical(Y)\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQW06SuxrRIs"
   },
   "outputs": [],
   "source": [
    "x_val, y_val =  load_validation_data((224, 224), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nXlIPNQgrRDI",
    "outputId": "38962139-c415-4fac-d795-081fab9e7883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 224, 224, 3) (10000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Xyd3qUhp0dd"
   },
   "source": [
    "### alex-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsvNseG__zz7"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bVcNPFj4pyid"
   },
   "outputs": [],
   "source": [
    "def create_alex_net():\n",
    "  np.random.seed(1000)\n",
    "\n",
    "  # (3) Create a sequential model\n",
    "  model = Sequential()\n",
    "\n",
    "  # 1st Convolutional Layer\n",
    "  model.add(Conv2D(filters=96, input_shape=(224, 224, 3), kernel_size=(11,11),strides=(4,4), padding='valid'))\n",
    "  model.add(Activation('relu'))\n",
    "  # Pooling \n",
    "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "  # Batch Normalisation before passing it to the next layer\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # 2nd Convolutional Layer\n",
    "  model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "  model.add(Activation('relu'))\n",
    "  # Pooling\n",
    "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # 3rd Convolutional Layer\n",
    "  model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "  model.add(Activation('relu'))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # 4th Convolutional Layer\n",
    "  model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "  model.add(Activation('relu'))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # 5th Convolutional Layer\n",
    "  model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "  model.add(Activation('relu'))\n",
    "  # Pooling\n",
    "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # Passing it to a dense layer\n",
    "  model.add(Flatten())\n",
    "  # 1st Dense Layer\n",
    "  model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "  model.add(Activation('relu'))\n",
    "  # Add Dropout to prevent overfitting\n",
    "  model.add(Dropout(0.4))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # 2nd Dense Layer\n",
    "  model.add(Dense(4096))\n",
    "  model.add(Activation('relu'))\n",
    "  # Add Dropout\n",
    "  model.add(Dropout(0.4))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # 3rd Dense Layer\n",
    "  model.add(Dense(1000))\n",
    "  model.add(Activation('relu'))\n",
    "  # Add Dropout\n",
    "  model.add(Dropout(0.4))\n",
    "  # Batch Normalisation\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(Dense(200))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJKNZy3rzkCN"
   },
   "outputs": [],
   "source": [
    "model = create_alex_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qRqPuCisEOv-",
    "outputId": "01e38a43-ccb6-4463-96f2-c3c1f2d7b05e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 200)               0         \n",
      "=================================================================\n",
      "Total params: 28,279,952\n",
      "Trainable params: 28,258,816\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uRRWuPH2SA9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "ZvcFsWBKx7JA",
    "outputId": "485564a5-e1e5-4105-d296-c155603e9732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/97 [=================>............] - ETA: 7:27 - loss: 3.6996 - acc: 0.1874"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0a7745f7a60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_gen, steps_per_epoch = 100000//1024, validation_data=(x_val, y_val), validation_steps= 10000//1024, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOKvKPY2_RQw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_loss_accuracy():\n",
    "  # plot loss\n",
    "  print(\"training_loss =\", hist.history['loss'][-1],  \"   val_loss =\", hist.history['val_loss'][-1])\n",
    "  print(\"training_acc =\", hist.history['acc'][-1]*100, \"   val_acc =\", hist.history['val_acc'][-1]*100)\n",
    "  plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "  plt.plot(hist.history['loss'], label='training_loss')\n",
    "\n",
    "  # plot accuracy\n",
    "  plt.plot(hist.history['val_acc'], label='val_acc')\n",
    "  plt.plot(hist.history['acc'], label='training_acc')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "jvk213mBXGUT",
    "outputId": "0c4a876e-4198-4b21-c861-00b95d97f3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss = 3.7227997037534224    val_loss = 3.72690825881958\n",
      "training_acc = 18.36303750259607    val_acc = 18.239999985694887\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2IIUEkoXH6y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "alex-net.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
